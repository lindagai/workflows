---
title: "Trio analysis for common and rare variants"
author:
- name: Linda Gai
  affiliation: Johns Hopkins School of Public Health
  email: lindagai@jhu.edu
output:
  BiocStyle::html_document
abstract: |
  Workflow for trio analysis for common and rare variants.
vignette: |
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r,echo=FALSE, message=FALSE, warning=FALSE}
knitr::opts_knit$set(root.dir = "/Users/lindagai 1/Documents/classes/4th year/Research/workflows/trio analysis/")
```

# Introduction

In this workflow, we will perform an example trio analysis on a VCF dataset of case-parent trios that has already undergone basic cleaning. If your datasets are not clean (or even if they are!), double-checking for cleanliness by consulting the [cleaning trio data workflow](https://github.com/lindagai/workflows/tree/master/cleaning%20trio%20data) is highly recommended.

We first perform common variants analysis using the `trio` [package from Bioconductor](https://www.bioconductor.org/packages/release/bioc/html/trio.html). We then show how to perform rare variants analysis: we first filter the rare variants sets into more informative variant sets, using position or annotation information, to increase power of the statistical tests. We then perform transmission disequilibrium tests for common variants using the trio package, and perform rare variant trio analysis using RV-TDT (Linux or Mac OS X required). Finally, we outline a few methods for plotting the results.

Our example dataset consists of whole-genome-sequencing data, containing 371 SNPs on a small region of chromosome 8, from 265 cleft palate case-parent trios (795 individuals) from the Gabriella Miller Kids First study. All individuals in the dataset are of Latino descent, and the data has genome build hg38.

# Setup
## R packages

This workflow uses the following R packages:

```{r, message=FALSE, warning=FALSE}
#Bioconductor
library(VariantAnnotation)
library(trio)
library(Gviz)
library(TxDb.Hsapiens.UCSC.hg38.knownGene)

#CRAN
library(dplyr)
library(ggplot2)
```

If you do not have them, run the following code:

```{r,eval = FALSE}
#Bioconductor
if (!requireNamespace("BiocManager", quietly = TRUE))
        install.packages("BiocManager")
BiocManager::install(c("VariantAnnotation", "trio",
                       "Gviz", "TxDb.Hsapiens.UCSC.hg38.knownGene"))

#CRAN
install.packages("dplyr")
install.packages("ggplot2")
```

Note that the code used in this workflow follows `tidyverse`-style conventions, including using `dplyr`-style pipes. A good guide to the `tidyverse`-style and conventions can be found [here](https://style.tidyverse.org/pipes.html).

## External software required for rare variant analysis

### RV-TDT

#### Install RV-TDT
RV-TDT can be installed and run on Linux and Mac OS X. Download the source code from Github [here](https://github.com/statgenetics/rv-tdt) and follow the directions to install RV-TDT.


#### Install rvtrio (R wrapper function)
You will need to give the filepath to RV-TDT to use the R wrapper function `RV_TDT` in `rvtrio`. To install rvtrio, run the following code:

```{r, eval=FALSE, warning=FALSE, message=FALSE}
devtools::install_github("lindagai/rvtrio")
library(rvtrio)
```

### Annotation information

To improve the power of statistical tests for rare variant analysis, it is often helpful to reduce the set of variants tested to those that are more likely to be disease-causing by using annotation information (e.g., we might filter our dataset to include variants that result in early stop codons, or have high functional annotation scores, since these variants are more likely to be disease-causing).

In this workflow, we are using ANNOVAR as the main source of functional annotation information, although many other resources exist; we describe some below.

### Haplotype phasing

Prior to rare variant analysis, you will need to phase the dataset (i.e., identifying which alleles in each individual are located on the same chromosomes). For most rare variant methods, we need to know which parent transmitted which alleles to the child to calculate the test statistics.

For trio data, we recommend using [BEAGLE 4.0](https://faculty.washington.edu/browning/beagle/b4_0.html) to phase, since it accounts for family information in phasing. As of May 2019, newer versions of BEAGLE (4.1 or 5.0) do not account for family structure and should be avoided for case-parent trio data.

#### Linux download
If you are using a Linux computing environment (e.g., most computing clusters), BEAGLE can be downloaded directly in the R console using the code chunk below:

```{r,eval = FALSE}
filepath.beagle4 <- "dir/where/you/want/beagle4/to/go/beagle.r1399.jar"
dl.beagle4 <- paste0("wget -O ",filepath.beagle4," https://faculty.washington.edu/browning/beagle/beagle.r1399.jar")
system(dl.beagle4)
```

#### Mac OS X download
If you are running the code on Mac OS X, you will need to instead run

```{r,eval = FALSE}
filepath.beagle4 <- "dir/where/you/want/beagle4/to/go/beagle.r1399.jar"
dl.beagle4 <- paste0("curl -o '",filepath.beagle4,"' http://faculty.washington.edu/browning/beagle/beagle.r1399.jar")
system(dl.beagle4)
```

# Common variants analysis {#test1}

In this workflow, we will consider 2 methods of common variant analysis: the allelic transmission disequilibrium test (aTDT) and genotypic transmission disequilibrium test (gTDT). Both aTDT and gTDT can be performed using the [`trio` package](https://www.bioconductor.org/packages/release/bioc/html/trio.html). `trio` accepts both PLINK ped files and VCF files, but we will use VCF files for this workflow.

## Select the genomic region you would like to analyze

A subset of a Tabix-indexed VCF can be read in using `VariantAnnotation`â€™s `param` parameter. In general, common variants analysis can be performed on an entire chromosome at once. However, to make sure that your code will run on your VCF, it might be good to first start with a smaller subset, e.g. a candidate gene.

In the code below, we demonstrate how to read in a particular region of interest (hg38:141000000-141030000).

```{r,eval = FALSE}
#BGZip and Tabix index the file first
fp.vcf <- "./data/raw_data/8q24.small.test.vcf" 
fp.vcf.bgz <- "./data/raw_data/8q24.small.test.vcf.bgz"

fp.zipped <- bgzip(fp.vcf, fp.vcf.bgz)
fp.indexed.tabix <- indexTabix(fp.zipped, format = "vcf")
fp.tabix <- TabixFile(fp.zipped, fp.indexed.tabix)

#Read in a small part of 8q24 region
rng <- GRanges(seqnames="chr8",
               ranges=IRanges(
                       start=c(141000000),
                       end=c(141030000)
               )
)

hg.assembly <- "hg38"

vcf.rng <- readVcf(fp.tabix, hg.assembly, param=rng)

#Check the genotype entries
table(geno(vcf.rng)$GT)

#Write out small region of interest
#The entire VCF is contained within the region of interest
# so it's the same file and we do not change the filename
filepath.common.vcf<-"./data/processed_data/8q24.small.test.vcf"
writeVcf(vcf.rng,filepath.common.vcf)
```

## Create a trio geno matrix

We begin by creating a `trio geno` object from a clean PED and VCF file:

### Read in PED file

1. The PED file should meet the following requirements:

    + all PIDs are present in VCF file and vice versa
    + families with large numbers of Mendelian errors are removed
    + contains 6 tab-delimited columns, in the following order:
        1. **famid** - family ID
        2. **pid** - personal ID unique to every individual in the data set
        3. **fatid** - father ID (only available for child cases)
        4. **motid** - mother ID (only available for child cases)
        5. **sex** - 1 if individual is male, 0 for female
        6. **affected** - 1 if individual is affected, 0 for unaffected
        
If some of these requirements are not met, please check the [cleaning workflow](https://github.com/lindagai/workflows/blob/master/cleaning%20trio%20data/cleaning_workflow.Rmd) for directions on how to create this file.
        
```{r}
filepath.ped<-"./data/raw_data/hg38.ped.txt"
ped <- read.table(filepath.ped,header=TRUE)
head(ped)
```

### Read in VCF file

2. The VCF for common variants analysis should meet the following requirements:

    + all PIDs in VCF are present in PED file and vice versa
    + families with large numbers of Mendelian errors are removed
    + genotype entries are in `"0/0"`, `"1/0"`, or `"1/1"` format; missing data is indicated by an `./.`
    
If some of these requirements are not met, please check the [cleaning workflow](https://github.com/lindagai/workflows/blob/master/cleaning%20trio%20data/cleaning_workflow.Rmd) for directions on how to create this file.

```{r}
filepath.common.vcf <- "./data/processed_data/8q24.small.test.vcf"
hg.assembly <- "hg38"
vcf <- readVcf(filepath.common.vcf, hg.assembly)

#Examine the genotype entries to make sure they're correct
table(geno(vcf)$GT)
```

Note that the number of SNPs is given by the number of rows, and the number of samples (e.g., number of individuals) is given by the number of columns. We can access this information using `dim`:

```{r}
dim(geno(vcf)$GT)
```

Here, our sample dataset contains 371 SNPs and 795 individuals.

### Make the `geno` matrix

The `geno` matrix is a matrix that is an input to the common variants tests, which has:

1. $3n$ rows, where $n$ = number of trios, where each row contains all the genotypes for a particular individual

2. $p$ columns, where $p$ = number of genomic sites under examination. Each entry is a `"0"`, `"1"`, or `"2"` (i.e., the number of minor alleles) at a particular genomic site.

Each block of 3 values is composed of the genotypes of the father, the mother, and the offspring (in this order) of a specific trio.

The `geno` object can be created using the `vcf2geno` function. Note that SNPs with missing entries (`./.`) are removed automatically from analysis. Similarly, monomorphic SNPs are also automatically removed.

```{r}
# allowDifference tells vcf2geno to not remove missing entries
# If you still want the missing entries to remain, set it to FALSEE
trio.geno <- vcf2geno(vcf, ped, allowDifference = TRUE)
trio.geno[1:5,1:5]
```

To check how many SNPs remain, we again use `dim`:
```{r}
dim(trio.geno)
```
248 SNPs remain.

#### Optional: Imputing missing SNP genotypes

If it turns out you have a lot of SNPs with missing genotypes, you can choose to impute missing genotypes in the VCF by phasing it using BEAGLE 4.0, which can be installed by following the directions in [Section 2.1.2](### Haplotype phasing) and can be run by following the directions in [Section 5](## Phasing). Then re-create the `geno` matrix after the missing observations have been imputed, and follow the directions for common variant testing below.

If you choose to do this, you will need to edit the genotype entries of the phased VCF prior to running the common variants tests: `trio` can only read in genotype entries `"0/0"`, `"0/1"`, or `"1/1"`, whereas a BEAGLE-phased VCF will contain genotype entries `"0|0"`, `"0|1"`, `"1|0"`, and `"1|1"`.

You can do this using the following code:

```{r, eval=FALSE}
phased.vcf <- readVcf(fp.phased.vcf, hg.assembly)

#Replace '|' with '/'
geno(phased.vcf)$GT<-gsub("\\|", "\\/",geno(phased.vcf)$GT)

#Replace '0/1' with '0/1'
geno(phased.vcf)$GT[geno(phased.vcf)$GT == "1/0"]<-"0/1"

#Write out the phased VCF
filepath.phased.common.var.vcf<-"./data/processed_data/phased.common.var.vcf"
writeVcf(phased.vcf,filepath.phased.common.var.vcf)
```

#### Remove SNPs with MAF > 0.05
It is recommended to limit the common variants analysis to common variants, i.e. we filter out SNPs with MAF < 0.05:

```{r}
trio.geno <- trio::removeSNPs(trio.geno, maf = 0.05)
```

Again, we check how many SNPs remain, using `dim`:

```{r}
dim(trio.geno)
```

Only 27 SNPs remain!

#### Save `geno` object

Note that the `geno` object may take a long time to load, so you may want to save it.
```{r}
filepath.trio.geno<-"./data/processed_data/trio_geno.RDS"
saveRDS(trio.geno, filepath.trio.geno)
```

## Genotypic TDT

The genotypic TDT is strongly recommended over the the allelic TDT, as the genotypic TDT can directly model the relative risk of disease, can be modified to account for additive, dominant, or recessive modes of inheritance, and can be modified to test for gene-environment interaction. In contrast, the allelic TDT can only report whether an allele is significant or not and must assume a multiplicative genetic model.

We demonstrate the gTDT for the additive model below. To use an alternative model, simply type in `"dominant"` or `"recessive"` instead of `"additive"`.

```{r}
#This can take awhile
#You may want to save it if you are working with large files
gTDT.results<-trio::colTDT(trio.geno, model = c("additive"))
gTDT.results %>% head
```

```{r}
#Create dataframe of genotypic TDT p-values and snp_names
gTDT.df <- data.frame(
        names(gTDT.results$pval),
        gTDT.results$stat, 
        gTDT.results$pval
        )
colnames(gTDT.df)<-c("snp","stat","pval")

gTDT.df <- gTDT.df %>% 
  arrange(pval) %>% 
  mutate(neglogp = -log(pval)) 

gTDT.df %>% head
```

## Allelic TDT

If desired, the aTDT can also be performed by trio. As of July 2019, the aTDT is considerably more popular than the gTDT (possibly because it is implemented in the popular PLINK software). In most cases, the aTDT and gTDT report similar results, but the gTDT has better statistical properties (citation).

```{r}
aTDT.results<-allelicTDT(trio.geno)
```
```{r}
#Create dataframe of allelic TDT p-values and snp_names
aTDT.df<-as.data.frame(cbind(aTDT.results$stat,aTDT.results$pval))
colnames(aTDT.df)<-c("stat","pval")

aTDT.df <- aTDT.df %>%
        arrange(pval) %>% 
        mutate(neglogp = -log10(pval))

aTDT.df %>% head
```

## Visualization
Basic Manhattan plots can be created with `ggplot2`. First, we must extract the position information from the VCF files, as the `trio` `geno` matrix does not contain position information.

### Extracting position and SNP IDs from the VCF
To get the genomic positions associated with each SNP quickly, we will specify that we only need to read in the FIXED field from the VCF, using `VariantAnnotation`'s `ScanVcfParam` object:

```{r, warning=FALSE}
fp.vcf<-"./data/processed_data/8q24.small.test.vcf"

## Return CHROM, POS, ID and REF from 'fixed' field
# do not read in other fields
svp <- ScanVcfParam(fixed="NA", info="NA", geno="NA")
vcf.svp <- readVcf(fp.vcf, "hg38", svp)

#Add SNP name and position to DF of results
snp<-names(vcf.svp)
pos<-start(rowRanges(vcf.svp))
snp.pos.df<-data.frame(snp,pos)
head(snp.pos.df)
```

We now merge the SNP/POS dataframe with the dataframe of results from aTDT and gTDT, so that we can create Manhattan plots. We use `dplyr::left_join` to only keep the position information of the SNPs present in the aTDT and gTDT results.

```{r}
gTDT.df<- left_join(gTDT.df,snp.pos.df)
head(gTDT.df)

aTDT.df <- data.frame(gTDT.df[,c("snp","pos")], aTDT.df)
head(aTDT.df)
```

If you plan to do rare variants analysis, save these results so that you can compare the common variants analysis to the rare variants analysis results.

```{r}
filepath.gTDT.results <- "./results/common_var/gTDT.results.txt"
write.table(gTDT.df, filepath.gTDT.results, sep = "        ", quote = FALSE, row.names = FALSE) 
        
filepath.aTDT.results <- "./results/common_var/aTDT.results.txt"
write.table(aTDT.df, filepath.aTDT.results, sep = "        ", quote = FALSE, row.names = FALSE)
```

### gTDT

```{r}
ggplot(gTDT.df)+
        geom_point(aes(x=pos,y=neglogp)) +
        labs(title="Genotypic TDT results",
             x="SNP position", y = "-log10p")
```

### aTDT
```{r}
ggplot(aTDT.df)+
        geom_point(aes(x=pos,y=neglogp)) +
        labs(title="Allelic TDT results",
             x="SNP position", y = "-log10p")
```

### Comparison across methods

A popular package for visualization genomic results is [Gviz](https://bioconductor.org/packages/release/bioc/html/Gviz.html). Here, we demonstrate how to create a simple graph in Gviz that compares results from the allelic and genotypic TDT results.


#### Set up initial ideograms of the genomic region

```{r}
#Basic information about the genetic region
chr <- "chr8"
from <- 141000000
to <- 141030000
regCode <- "8q24"
gen <- "hg38"

#Set up initial tracks
itrack <- IdeogramTrack(genome = gen, chromosome = chr, showBandId = TRUE,
                        cex.bands=0.8#, 
                        #showID=TRUE
                        )

gtrack <- GenomeAxisTrack()
```

#### Add the gene region track
```{r}
txdb <- TxDb.Hsapiens.UCSC.hg38.knownGene

#Get the gene region track for the database results in the relevant region
txTr <- GeneRegionTrack(txdb, genome = gen, chromosome = chr,
                        start = from, end = to, name = "Genes", showId=TRUE,
                        geneSymbols=TRUE, collapseTranscripts="meta", 
                        col.title="black", cex.title=0.8#, cex.group=0.8
                        )
```

#### Add gTDT results

```{r}
#A. gTDT track
filepath.genotypic.tdt.results <- "./results/common_var/gTDT.results.txt"
genotypic.tdt.results <- read.table(filepath.genotypic.tdt.results,header=TRUE)
genotypic.tdt.results %>% head
log10p.gTDT <- -log10(genotypic.tdt.results$pval)

dtrack.gTDT <- DataTrack(data=log10p.gTDT,
                         start=genotypic.tdt.results$pos-1,
                         end=genotypic.tdt.results$pos,
                         genome="hg38", chromosome="chr8",
                         name= "-log10p (gTDT)",
                         ylim=c(-0.5,2),
                         baseline=0, v=0, col.line="grey92",
                         cex=2,
                         cex.title=1, col.title="black", 
                         col.axis="black")

```

#### Add aTDT results

```{r}
filepath.allelic.tdt.results<-"./results/common_var/aTDT.results.txt"
allelic.tdt.results <- read.table(filepath.allelic.tdt.results,header=TRUE)
allelic.tdt.results  %>% head
log10p.aTDT <- -log10(allelic.tdt.results$pval)

dtrack.aTDT <- DataTrack(data=log10p.aTDT,
                         start = allelic.tdt.results$pos-1,
                         end = allelic.tdt.results$pos,
                         genome="hg38", chromosome="chr8",
                         name= "-log10p (gTDT)",
                         ylim=c(-0.5,2),
                         baseline=0, v=0, col.line="grey92",
                         cex=2,
                         cex.title=1, col.title="black", 
                         col.axis="black")
```

#### Build the graph:

```{r fig1, fig.height = 10, fig.width = 10, fig.align = "center"}
plotTracks(list(itrack,
                txTr,
                gtrack,
                dtrack.gTDT,
                dtrack.aTDT),
background.title="darkgray",from= from, to=to)
```

# Rare variants analysis

## Phasing

Haplotype phasing allows us to identify alleles located on the same chromosome in 1 individual (an excellent overview of the process can be found [here](https://data-science-sequencing.github.io/Win2018/lectures/lecture10/)). Most of the rare variant analysis methods used here require knowing which parent transmitted which particular variants for the variants to be weighted appropriately, so phasing is generally recommended.

Here, we will use BEAGLE to perform haplotype phasing, as well as imputation of missing genotypes and alleles.

### Selecting the subset of chromosome to phase

**Phasing takes a long time**, so it is often preferable to identify a relatively small region of interest prior to phasing (e.g., subsetting the VCF to a candidate gene). However, phasing uses the nearby variants to make inferences about which parent transmitted which alleles and to impute missing observations, so you will need to include "buffer windows" on either side of the candidate gene to ensure that variants within the region of interest are phased correctly.

Since our example dataset is a small subset of 8q24 (hg38:141000000-143000000), we cannot subset to an entire candidate gene. Here, we are going to instead choose to examine a subset of the example dataset (hg38:141015000-141025000), and choose a buffer window size of 1000 kB. Note that **common variants MUST be included in the VCF** for phasing.

```{r,eval = FALSE}
#4.1.1 Selecting the subset of chromosome to phase
#You will need to Tabix index and bgzip the file prior to reading in a small region using param
fp.vcf <- "./data/processed_data/8q24.small.test.vcf"
fp.vcf.bgz <- "./data/processed_data/8q24.small.test.vcf.bgz"

fp.zipped <- bgzip(fp.vcf, fp.vcf.bgz)
fp.indexed.tabix <- indexTabix(fp.zipped, format = "vcf")
fp.tabix <- TabixFile(fp.zipped, fp.indexed.tabix)

#Specify interval of interest and buffer size
start <- 141015000
end <- 141025000
buffer.window.size <- 1000

rng <- GRanges(seqnames="chr8",
               ranges=IRanges(
                       start = start - buffer.window.size ,
                       end = end + buffer.window.size)
               )

#Read in subset
hg.assembly <- "hg38"
vcf.rng <- readVcf(fp.tabix, hg.assembly, param=rng)

#Check how many SNPs remain
geno(vcf.rng)$GT %>% dim
#139 795

#Write out
fp.vcf.to.phase <- "./data/processed_data/vcf.to.phase.vcf"
writeVcf(vcf.rng, fp.vcf.to.phase)
```

### Phasing the dataset

Phasing can be done in the R console with the below code. Note that this step may take a long time, so be sure that the file you want to phase has been subsetted to the gene or region of interest.

```{r,eval = FALSE}
#NOTE: You do not need to include ".vcf" in the output VCF filename
#BEAGLE adds .vcf.gz to the filename automatically
fp.phased.vcf <- "./data/processed_data/phased"

phase.command <- paste0("java -Xmx10000m -jar ", fp.beagle4,
                      " gt=",fp.vcf.to.phase,
                      " ped=",fp.ped,
                      " out=",fp.phased.vcf)
phase.command

system(phase.command)
```

## Filter the VCF to rare variants only and remove monomorphic SNPS
```{r,eval = FALSE}
#Read in and check genotype entries
filepath.phased.vcf <- "./data/processed_data/phased.vcf.gz"
hg.assembly <- "hg38"
vcf <- readVcf(filepath.phased.vcf, hg.assembly)
table(geno(vcf)$GT)

#Calculate MAFs
maf.matrix <- geno(vcf)$GT

#Replace genotypes with minor allele counts
maf.matrix[maf.matrix == "0|0"]<- 0
maf.matrix[maf.matrix == "1|0"]<- 1
maf.matrix[maf.matrix == "0|1"]<- 1
maf.matrix[maf.matrix == "1|1"]<- 2

#Convert from string to numeric vector
maf.matrix <- type.convert(maf.matrix)

#Get MAF of each SNP
#Divide by 2 because there are 2 alleles per individual
maf.matrix <- rowMeans(test)/2
range(maf.matrix)

#Identify SNPs with MAF < 0.01 and remove monomorphic SNPS
rare.var.snps <- names(which(maf.matrix < 0.01 & maf.matrix != 0))
rare.var.snps %>% head
rare.var.snps %>% length

#Filter VCF to rare variants only
vcf.rare <- vcf[which(names(rowRanges(vcf)) %in% rare.var.snps),]

table(geno(vcf.rare)$GT)

#Write out VCF
fp.rare.vcf <- "./data/processed_data/rare.var.vcf"
writeVcf(vcf.rare, fp.rare.vcf)
```

## Types of additional filtering
To enrich rare variant signal, it is often helpful to filter the dataset under analysis to probable causal variants or candidate genes. Below we discuss a few types of filters you may consider:

### Filtering by annotation information
One way to enrich signal is to filter the variant set to probable causal variants, using annotation information. For example, one could filter the VCF using functional annotation scores like CADD, which measures "deleteriousness" by ; alternatively, one could choose variants that result in stop codons, etc.

### Filter by position
If you have a priori information on whether a particular genomic region is linked to an increase in disease risk, it can be wise to filter the set of variants using the position of the variant. For example, in the 8q24 region, previous work has shown that common variants in 129.9-130.1 Mb on genome build hg19 have been implicated in increasing cleft palate risk in European case-parent trios (citation). We replicated this finding in the common variants analysis section. Filtering to only the set of variants that is contained within this region, then, could be a good way to increase the proportion of probable causal variants in the test set.

### Choosing a window size
Another option to enrich signal is to adjust the window size (i.e., the number of "consecutive" markers in each test set). Disease-causing variants tend to be located relatively close together, compared to benign variants, so grouping together consecutive sets of variants is another option to aggregate together disease-risk from multiple variants (citation). The ideal size of the window can be selected on a priori knowledge and/or by trying multiple sizes. 

For example, if you have already done a common variants analysis and discovered a region enriched with common variant signal, choosing a window size that contains the entire region could be a good idea. Another option would be to test windows of many sizes, ranging from 2-25 markers. Alternatively, one can just try many sizes and choose the window size -- in the original Scan-Trio paper (link), window sizes of 2-25 markers were tested.

## Exploratory data analysis and filtering the VCF

Prior to filtering, performing EDA on the annotation information on the region of interest will allow you to better select filters well-suited to your analysis.

### Common variant signal
In [Section 3.5.2](### gTDT) and [Section 3.5.3](### aTDT), the region on 141.015- 141.025 Mb on genome build hg38 appears to be associated with an increased risk of cleft palate in the example dataset, using both the gTDT and the aTDT. 

A natural variant set to test, then, might be the region within the area of peak common variant signal. To be able to read in a subset of the VCF, we will need to re-bgzip and index the phased vcf that contains only rare variants. We can then subset the VCF:

```{r,eval = FALSE}
fp.rare.vcf <- "./data/processed_data/rare.var.vcf"
fp.vcf.bgz <- "./data/raw_data/rare.var.vcf.bgz"

fp.zipped <- bgzip(fp.rare.vcf, fp.vcf.bgz)
fp.indexed.tabix <- indexTabix(fp.zipped, format = "vcf")
fp.tabix <- TabixFile(fp.zipped, fp.indexed.tabix)

#Read in region with highest signal based on common variant results

a <-141015000
b <-141025000

rng <- GRanges(seqnames="chr8",
               ranges=IRanges(
                       start = a,
                       end = b)
               )

hg.assembly <- "hg38"

vcf.rare.filtered <- readVcf(fp.tabix, hg.assembly, param=rng)

#Check how many SNPs remain
geno(vcf.rng)$GT %>% dim

#Write out small region of interest
fp.rare.filtered.vcf <- "./data/processed_data/rare.var.filtered.vcf"
writeVcf(vcf.rare.filtered, fp.rare.filtered.vcf)
```
### Annotation information

Filtering the VCF to variants that have high functional annotation scores that indicate potential deleteriousness can increase the power of rare variant tests to detect potential association with disease risk. Some functional annotation scores you might consider using are CADD, EIGEN, PolyPhen, and SIFT.

Many functional annotation scores are available in large databases that can be downloaded. Although a walkthrough of these methods is beyond the scope of these workflow, we recommend some sources of annotation information below.

#### **Annotation on Bioconductor**
Bioconductor contains many annotation databases that can be downloaded using R and have excellent, detailed walkthroughs.

##### **EnsemblVEP **
EnsemblVEP is a popular program for annotating VCF files, and can be easily installed locally using [Bioconda](https://bioconda.github.io/recipes/ensembl-vep/README.html), assuming you have Perl on your computer. It also has R wrapper functions in the Bioconductor package [ensemblVEP](https://bioconductor.org/packages/release/bioc/html/ensemblVEP.html).

Annotating a VCF with EnsemblVEP allows the user to use the excellent VCF filtering tools in Bioconductor's The VCF Tool Box package, also known as [TVTB](https://bioconductor.org/packages/release/bioc/vignettes/TVTB/inst/doc/Introduction.html). 

##### **AnnotationHub**

[AnnotationHub](https://bioconductor.org/packages/release/bioc/html/AnnotationHub.html) is another [well-documented](https://kasperdanielhansen.github.io/genbioconductor/html/AnnotationHub.html) Bioconductor package that allows R users to easily access several annotation databases. Note that, as of August 2019, most of the most updated annotation databases for humans (e.g. annotation databases for hg38) are for evolutionary conservation (e.g. PhyloPhen), not functional annotation or deleteriousness (e.g. CADD or PolyPhen).

#### External software for annotation

##### **ANNOVAR** 

ANNOVAR is a software tool for annotating genetic variants, which can be downloaded from their website [here](http://annovar.openbioinformatics.org/en/latest/). ANNOVAR will produce a .txt report with functional annotation scores, positions with stop-codons, which can then be used to filter the VCF to potentially causal variants prior to rare variant analysis.

#### **1000 Genomes**

### Write out

When you are done filtering your VCF to your desired rare variant set, write it out:

```{r,eval = FALSE}
#Write out small region of interest
fp.rare.filtered.vcf <- "./data/processed_data/rare.var.filtered.vcf"
writeVcf(vcf.rare.filtered, fp.vcf.rare.filtered)
```

## Analysis methods

Once you have your filtered rare variant set, you can finally start doing some rare variant analysis! We first read in the cleaned PED file, as the well as the filtered VCF:

```{r}
fp.ped<-"./data/raw_data/hg38.ped.txt"
ped <- read.table(fp.ped,header=TRUE)
head(ped)

fp.rare.filtered.vcf <- "./data/processed_data/rare.var.filtered.vcf"
hg.assembly <- "hg38"
vcf <- VariantAnnotation::readVcf(fp.rare.filtered.vcf, hg.assembly)
```

### RV-TDT
RV-TDT can be run on both the entire VCF at once -- this gives you one "window" that contains all the SNPs in the VCF.

Note that you will have to provide the filepath to RV-TDT on your computer to use wrapper function:

```{r,eval = FALSE}
filepath.to.RV_TDT <- "where/you/downloaded/RV-TDT"

#Run on the entire VCF (i.e. 1 window)
RV_TDT.results<-rvtrio::RV_TDT(vcf=vcf, vcf.ped = ped,
                               rv.tdt.dir = filepath.to.RV_TDT)
```

```{r,echo = FALSE}
filepath.to.RV_TDT <- "/Users/lindagai 1/Documents/classes/4th year/Research/rv-tdt-master/rvTDT"

#Run on the entire VCF (i.e. 1 window)
RV_TDT.results<-rvtrio::RV_TDT(vcf=vcf, vcf.ped = ped,
                               rv.tdt.dir = filepath.to.RV_TDT)
```

It can also be run on sliding windows containing a user-specified number of markers -- here, we'll use 25 markers as an example. Doing sliding windows can take a long time, so you may want to save it.

```{r}
#Run RV-TDT on 25-marker windows
win.size <- 25
RV_TDT.results <- rvtrio::RV_TDT(vcf=vcf, vcf.ped = ped, rv.tdt.dir = filepath.to.RV_TDT, 
                                 window.size = win.size, upper_cutoff=0.01)
head(RV_TDT.results)
```

```{r}
#Save, if desired
fp.rv_tdt.results <- paste0("./results/rare_var/RV_TDT.", win.size, "M.txt")
write.table(RV_TDT.results, fp.rv_tdt.results, sep = "        ", quote = FALSE, row.names = FALSE)
head(RV_TDT.results)
```

## Visualization
### RV-TDT

To graph RV-TDT results for multiple windows, it must be converted into long format. That is, each row represents a window tested by a specific test in RV-TDT, and `test` is a column indicating which RV-TDT was performed.

```{r}
n.windows<-nrow(RV_TDT.results)

#Convert to long format
RV_TDT.results.long <- RV_TDT.results %>%
        tidyr::gather(key = test, value = pval,
        CMC.Analytical,BRV.Haplo,CMC.Haplo,VT.BRV.Haplo,VT.CMC.Haplo,WSS.Haplo)

RV_TDT.results.long %>% head
```

As we are testing multiple windows, we need to perform a Bonferonni correction on the significance level, shown in the graph below.



```{r}
#Bonferroni corrected
bonferroni.sig.level <- -log10(0.05/n.windows)

#Plot
ggplot() +
  geom_line(data = RV_TDT.results.long, aes(group=test, color = test,
                               x = mid.window.pos, y = -log10(pval)))+
    geom_hline(yintercept=bonferroni.sig.level, linetype=2, color = "red", size=2) +
    labs(title='RV-TDT results for window size = 25 SNPs, 24 SNP overlap',
         x ='Position (hg38)', y = '-log10p-value at center of window')+
    guides(color=guide_legend("RV-TDT test type")) +
  scale_linetype_manual(name = "Bonferroni-corrected significance", values = 2,
                        guide = guide_legend(override.aes = list(color = c("red"))))
```

### Comparison across methods

To compare the results from the common variants analysis to the rare variants analyses directly, we can use the GViz package. 

#### Basic gene tracks

```{r}
chr <- "chr8"
from <- 141000000
to <- 141030000
regCode <- "8q24"
gen <- "hg38"

#Set up initial tracks
itrack <- IdeogramTrack(genome = gen, chromosome = chr, showBandId = TRUE,
                        cex.bands=0.8, 
                        showID=TRUE
)

gtrack <- GenomeAxisTrack()

txdb <- TxDb.Hsapiens.UCSC.hg38.knownGene

#Get the gene region track for the database results in the relevant region
txTr <- GeneRegionTrack(txdb, genome = gen, chromosome = chr,
                        start = from, end = to, name = "Genes", showId=TRUE,
                        geneSymbols=TRUE, collapseTranscripts="meta", 
                        col.title="black", cex.title=0.8#, cex.group=0.8
)
```

#### Optional: Common variants analysis tracks
We then add the tracks used in the [common variants analysis](# Common variants analysis).
        
```{r}
        
#A. gTDT track
filepath.genotypic.tdt.results <- "./results/common_var/gTDT.results.txt"
genotypic.tdt.results <- read.table(filepath.genotypic.tdt.results,header=TRUE)
genotypic.tdt.results %>% head
log10p.gTDT <- -log10(genotypic.tdt.results$pval)

genotypic.tdt.results %>% head

dtrack.gTDT <- DataTrack(data=log10p.gTDT,
                         start=genotypic.tdt.results$pos-1,
                         end=genotypic.tdt.results$pos,
                         genome="hg38", chromosome="chr8",
                         name= "-log10p (gTDT)",
                         ylim=c(-0.5,2),
                         baseline=0, v=0, col.line="grey92",
                         cex=2,
                         cex.title=1, col.title="black", 
                         col.axis="black")

#B. aTDT track
filepath.allelic.tdt.results<-"./results/common_var/aTDT.results.txt"
allelic.tdt.results <- read.table(filepath.allelic.tdt.results,header=TRUE)
allelic.tdt.results  %>% head
log10p.aTDT <- -log10(allelic.tdt.results$pval)

dtrack.aTDT <- DataTrack(data=log10p.aTDT,
                         start = allelic.tdt.results$pos-1,
                         end = allelic.tdt.results$pos,
                         genome="hg38", chromosome="chr8",
                         name= "-log10p (aTDT)",
                         ylim=c(-0.5,2),
                         baseline=0, v=0, col.line="grey92",
                         cex=2,
                         cex.title=1, col.title="black", 
                         col.axis="black")
        
```

#### Transmitted rare variants track

`rvtrio` includes a function, `getTransmittedRareVarCounts`, that will calculate the number of times a rare variant has been transmitted. We can use this function to create a graph of the number of times rare variants were transmitted:
                
```{r}
fp.ped<-"./data/raw_data/hg38.ped.txt"
ped <- read.table(fp.ped,header=TRUE)
head(ped)

#Read in phased VCF that is rare variants only
#(i.e., only includes rare variants that you've included in your RV-TDT)
filepath.phased.vcf <- "./data/processed_data/phased.vcf.gz"
hg.assembly <- "hg38"
vcf <- readVcf(filepath.phased.vcf, hg.assembly)
table(geno(vcf)$GT)

#Get # of rare variants that are transmitted from parents to offspring
transmitted.rare.var.ct <- rvtrio::getTransmittedRareVarCounts(vcf, ped)

#Transmitted rvs
max.trans.rv <- max(transmitted.rare.var.ct$trans.ct)

dtrack.transmitted.rv <- DataTrack(data=transmitted.rare.var.ct$trans.ct,
                                   start=transmitted.rare.var.ct $pos-1,
                                   end=transmitted.rare.var.ct$pos,
                                   genome="hg38", chromosome="chr8",
                                   name= "Transmitted Rare Variants",
                                   cex.title=1, col.title="black",
                                   ylim=c(-0.5, max.trans.rv + 1),
                                   baseline=0, v=0, col.line="grey92",
                                   col.axis="black")

```

#### RV-TDT track
```{r}
### Create the RV-TDT track

#Read in results
win.size <- 25
fp.rv_tdt.results <- paste0("./results/rare_var/RV_TDT.", win.size, "M.txt")
RV_TDT.results <- read.table(fp.rv_tdt.results, header=TRUE)

#Convert to long format
RV_TDT.results.long <- RV_TDT.results %>%
        tidyr::gather(key = test, value = pval,
                      CMC.Analytical,BRV.Haplo,CMC.Haplo,VT.BRV.Haplo,VT.CMC.Haplo,WSS.Haplo)

#Plot all tests using an OverlayTrack
tests <- levels(factor(RV_TDT.results.long$test))
n.tests <- length(tests)

rv_tdt.tracks <- vector(mode = "list", length = n.tests)

for (i in 1:n.tests){
        curr.test <- tests[i]
        curr.subset <- RV_TDT.results.long %>%
                filter(test == curr.test)
        
        rv_tdt.tracks[[i]] <- DataTrack(data = -log10(curr.subset$pval),
                                        start = curr.subset$start.pos,
                                        end = curr.subset$end.pos,
                                        genome = "hg38", chromosome = "chr8",
                                        name = "-log10p (RV-TDT)",
                                        ylim=c(-0.5, 2),
                                        baseline=0, 
                                        col.baseline="black",
                                        col.axis="black",
                                        fontcolor="black",
                                        groups=factor(curr.test, levels=tests),
                                        legend=TRUE)       
}


ot.rv_tdt.tracks <- OverlayTrack(trackList=rv_tdt.tracks)

```

##### Create graph
```{r}
all.tracks <- c(list(itrack,
                     txTr,
                     gtrack,
                     dtrack.gTDT,
                     dtrack.aTDT,
                     dtrack.transmitted.rv), ot.rv_tdt.tracks)

plot.types <- c("p",
                rep("a", n.tests)
)
plotTracks(all.tracks, background.title="darkgray", type = plot.types, from= from, to=to)
        
```

```{r fig2, fig.height = 10, fig.width = 10, fig.align = "center"}
plotTracks(all.tracks, background.title="darkgray", type = plot.types, from= from, to=to)
```


# Troubleshooting

## RV-TDT

### Segmentation fault: 11
This is usually caused by one of the input files (ped, tped, or map) to RV-TDT not being formatted correctly. `rvtrio` provides some automatic checks for this, but you should double-check the VCF and PED files on your own if you are still getting this error.

### Produces output file, but no results
A possible explanation is that your file sizes might be too large for RV-TDT to handle. Try testing a smaller window size (e.g., test a window size < 500M, or use an input VCF that contains fewer than 500 SNPs).

# Concluding remarks

```{r sessionInfo, echo=FALSE}
sessionInfo()
```
