---
title: "Cleaning VCF data from case-parent trio studies for common and rare variants analysis"
author:
- name: Linda Gai
  affiliation: Johns Hopkins School of Public Health
  email: lindagai@jhu.edu
output:
  BiocStyle::html_document
abstract: |
  Workflow for cleaning case-parent trio data to prepare for common and rare variants analysis.
vignette: |
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,echo=FALSE, message=FALSE, warning=FALSE}
knitr::opts_knit$set(root.dir = "/Users/lindagai 1/Documents/classes/4th year/Research/workflows/cleaning trio data")
library(magick)
```

# Introduction

In this workflow, we will clean an example VCF dataset of case-parent trios. After completing this workflow, an analyst can then follow the steps in the [trio analysis workflow](https://github.com/lindagai/workflows/tree/master/trio%20analysis) to test both common variants and rare variants for association with increased disease risk.

Our example dataset consists of whole-genome-sequencing data, containing 110 SNPs on a small region of chromosome 8, from 332 cleft palate case-parent trios (996 individuals) from the Gabriella Miller Kids First study. All individuals in the dataset are of European descent, and the data has genome build hg19.

# Setup


## R packages

This workflow uses the following R packages:

```{r, warning=FALSE, message=FALSE}
#Bioconductor
library(VariantAnnotation)
library(trio)

#CRAN
library(dplyr)
library(ggplot2)
```

If you do not have them, run the following code:

```{r,eval = FALSE}
#Bioconductor
if (!requireNamespace("BiocManager", quietly = TRUE))
        install.packages("BiocManager")
BiocManager::install(c("VariantAnnotation", "trio"))

#CRAN
install.packages("dplyr")
install.packages("ggplot2")
```

Note that the code used in this workflow follows `tidyverse`-style conventions, including using `dplyr`-style pipes. A good guide to the `tidyverse`-style and conventions can be found [here](https://style.tidyverse.org/pipes.html).

# Optional: Reading in subsets of a VCF

If your VCF file is very large, or you plan on filtering the VCF for rare variant analysis, Tabix indexing the VCF prior to analysis is highly recommended. Tabix indexing allows us to efficiently read in small parts  as well as filter the VCF using the Bioconductor package `VariantAnnotation`.

## Tabix-indexing a VCF
First, we index the VCF using `indexTabix`:

```{r, eval=FALSE}
# NOTE: none of the functions here will overwrite existing files,
# so if you've already created the .bgz and .tbi files,
# this code block will not run

filepath.vcf <- "./data/8q24.hg19.small.test.vcf"
fp.vcf.bgz <- "./data/8q24.hg19.small.test.vcf.bgz"

fp.zipped <- bgzip(fp.vcf, fp.vcf.bgz)
fp.indexed.tabix <- indexTabix(fp.zipped, format = "vcf")
fp.tabix <- TabixFile(fp.zipped, fp.indexed.tabix)
```

## Reading in a subset of a Tabix-indexed VCF
Now we can define the region of interest using a `GRanges` object `rng`:

```{r, eval=FALSE}
start.pos <- 130000000
end.pos <- 130005000

rng <- GRanges(seqnames="chr8",
               ranges=IRanges(
                       start=c(start.pos),
                       end=c(end.pos)
               )
)
```

Finally, we can read in only the subset of the VCF we are interested in, by setting `readVcf`'s `param` to the set of ranges in `rng`.

```{r, eval=FALSE}
hg.assembly <- "hg19"

vcf.rng <- readVcf(fp.tabix, hg.assembly, param=rng)

#Write out small region of interest
#Here, the entire VCF is contained within the region of interest
# so it's the same file and we do not change the filename
filepath.vcf<-"./data/processed_data/8q24.small.test.vcf"
writeVcf(vcf.rng,filepath.vcf)
```

# Cleaning your VCF file prior to analysis

## Example data set

For the example analysis, we will begin by cleaning a raw VCF dataset consisting of 996 case-parent trios affected with cleft lip, with or without cleft palate (CL/P) with 110 SNPs. (Note that the genotype entries have been modified from the original data to better illustrate the process of data cleaning.)

```{r}
filepath.vcf <- "./data/8q24.hg19.small.test.vcf"
hg.assembly <- "hg19"
vcf <- VariantAnnotation::readVcf(filepath.vcf, hg.assembly)
vcf
```

To start with, we need to check to make sure the VCF is clean and in the correct format. We first check the genotype entries to ensure that they are in the correct format:

```{r}
table(geno(vcf)$GT)
```

`geno` is an accessor function that obtains genotype data described in the `FORMAT` fields of the VCF, and `GT` is the matrix of genotypes for each individual. Each entry in `GT` gives the genotype for a particular individual at a particular SNP. Each row in `GT` corresponds to a particular SNP, and each column corresponds to an individual (or sample). Additional information on using `VariantAnnotation` for manipulating VCFs can be found [here](https://bioconductor.org/packages/release/bioc/vignettes/VariantAnnotation/inst/doc/VariantAnnotation.pdf).

## Optional: missing and half-calls
Looking at the above output, we can see that we have missing calls (`.`), as well as half-calls (`0/.` and `1/.`). If you don't plan on phasing, and don't plan on performing rare variants analysis, you can skip this part  -- during common variants analysis, `trio` will remove SNPs that contain missing entries automatically for you.

But if you plan on [imputing missing values and phasing using phasing software](### Optional: Imputing missing SNP genotypes) -- which is required for rare variants analysis --  set the half-calls to missing, and change the `.` entries to `./.`, to ensure that BEAGLE can read in the VCF entries correctly.

```{r}
geno(vcf)$GT[geno(vcf)$GT == "."] <- "./."
geno(vcf)$GT[geno(vcf)$GT == "1/."] <- "./."
geno(vcf)$GT[geno(vcf)$GT == "0/."] <- "./."
```

## Remove duplicated sites and multi-allelic SNPs
Most trio analysis methods are only for bi-allelic SNPs, so we remove multi-allelic sites with the code below.

```{r}
duplicate.sites <- start(rowRanges(vcf))[duplicated(start(rowRanges(vcf)))]

#How many sites are in the raw VCF?
start(rowRanges(vcf)) %>% length

#How many sites are duplicated?
duplicate.sites %>% length

vcf <- vcf[-which(start(rowRanges(vcf)) %in% duplicate.sites),]
```

`start(rowRanges(vcf))` accesses the genomic position for each genotype in the VCF. 

A thorough understanding of the other functions described in the above block of code is not necessary for understanding the rest of this workflow, but is helpful for understanding how VCF files are organized and how genomic information in Bioconductor-style objects. `rowRanges` accesses information from the [CHROM, POS, and ID fields of the VCF file](https://grunwaldlab.github.io/Population_Genetics_in_R/reading_vcf.html), which is represented as a `GRanges` object. `GRanges` objects are used to store genomic locations within the Bioconductor project. A good introduction to `GRanges` objects can be found [here](https://bioconductor.org/packages/release/bioc/vignettes/GenomicRanges/inst/doc/GenomicRangesIntroduction.html).

## Check for Hardy-Weinberg equilibrium

We can check for Hardy-Weinberg equilibrium in the SNPs using `VariantAnnotation`'s `snpSummary` function.

```{r}
snp.summary <- snpSummary(vcf) %>%
        tibble::rownames_to_column(var = "snp") 

#Set the rownames as a column so dplyr will preserve them
snp.summary %>%
        dplyr::arrange(HWEpvalue) %>%
        head
```

No SNPs are significant (p < 0.05), so we don't remove them in this case. However, if we wanted to remove them, you can use the following code:

```{r, eval=FALSE}
snps.to.remove <- snp.summary %>%
        select(snp, HWEpvalue) %>%
        filter(HWEpvalue < 0.05) %>%
        select(snp) %>%
        unlist  

vcf <- vcf[-which(names(rowRanges(vcf)) %in% snps.to.remove),]
```

## Write out
Depending on the size of your file and the power of your computer, even reading in the VCF and checking for missing observations can be quite time-consuming. As such, it can be a good idea to write out the VCF after each time-consuming step:

1. You avoid the need to re-run your previous work if you mess up.
2. File I/O is slow, but running many of the functions described in this workflow is often even slower.
3. If you need to alter the code provided in any way, having files saved at intermediate steps often allows for easier debugging (though ideally you have also integrated [automated testing/debugging](https://kbroman.org/pkg_primer/pages/tests.html) into your workflow as well!).

So save time by saving your steps! `VariantAnnotation` has a convenient function for writing out VCFs:

```{r,eval = FALSE}
filepath.filtered.vcf <- "your filepath here"
writeVcf(vcf,filepath.filtered.vcf)
```

# Cleaning your PED file prior to analysis
Generally, pedigree information is not included in the VCF file itself, but in a separate PED file, a text file containing 6 columns:

1. **famid** - family ID
2. **pid** - personal ID unique to every individual in the data set
3. **fatid** - father ID (only available for child cases)
4. **motid** - mother ID (only available for child cases)
5. **sex** - 1 if individual is male, 0 for female
6. **affected** - 1 if individual is affected, 0 for unaffected

Note that this is the same format as the first 6 columns of the PLINK PED file, a popular alternative filetype for storing genomic data.

The raw PED file accompanying the test VCF is shown below:

```{r}
filepath.ped <- "./data/gmkf_euro_completetrios.csv"
ped <- read.csv(filepath.ped,header=TRUE, stringsAsFactors = FALSE)
head(ped)
```

## Ensure column names are correct
Looking at the top 10 lines of the file, we see that the columns need to be renamed. We will do so using `dplyr`-style pipes: 

```{r}
ped <- ped %>%
  rename("famid"="Family.ID",
         "pid"="Individual.ID",
         "fatid"="Father.ID",
         "motid"="Mother.ID",
         "sex" = "Gender",
         "affected"="Clinical.Status")
```

## Select only the necessary columns
```{r}
ped <- ped %>%
        select( "famid", "pid", "fatid", "motid", "sex","affected")
head(ped)
```

## Ensure sex and affected are coded as 1/0, not "male/female" or "affected/unaffected"

```{r}
ped <- ped %>%
        mutate(sex = ifelse(sex == "male", 1, 0)) %>%
        mutate(affected = ifelse(affected == "Affected", 1, 0))

ped %>% head
```

## Ensure the all PIDs in the VCF and PED files match in format
All subjects in the VCF must also appear (with the same ID) in the PED file, and vice versa.

We first manually check to see if the first few PIDs in the PED and VCF look the same:

```{r}
#Examine PIDs in VCF and PED
vcf.pid <- colnames(geno(vcf)$GT)
vcf.pid %>% head
```
```{r}
ped$pid %>% 
        factor %>%
        head
```

Clearly, the VCF PIDs are different from the PED PIDs. Closer examination reveals that the PIDs in the VCF look like the pids from the PED pasted together twice, with a prefix of "HTZ-". Modify the PED PIDs accordingly:
```{r}
#Modify PIDs in PED to match VCF
ped <- ped %>%
        mutate(pid = paste0("H_TZ-",pid,"-",pid)) %>%
        mutate(fatid = ifelse(fatid == 0, "0",
                              paste0("H_TZ-",fatid,"-",fatid))) %>%
        mutate(motid = ifelse(motid == 0, "0",
                              paste0("H_TZ-",motid,"-",motid)))
```

## Identify any PIDs in VCF but not in PED and vice versa

Now, we check to see whether there are any PIDs in the VCF that aren't in the PED file:

```{r}
setdiff(vcf.pid,ped$pid)
```
And whether there are any PIDs in the PED file that aren't in the VCF:
```{r}
setdiff(ped$pid,vcf.pid)
```

A few individuals in the VCF have a "B" appended to the end of their PID! Modify these in the PED file:

```{r}
#These IDs in VCF contain a B, so we edit them in PED
pids.to.edit <-setdiff(ped$pid,vcf.pid)
pids.to.edit

#Remember to change the fatid and motid as well!
ped <- ped %>%
        mutate(pid =  ifelse(pid %in% pids.to.edit,
               paste0(pid,"B"),pid)) %>%
        mutate(fatid =  ifelse(fatid %in% pids.to.edit,
                             paste0(fatid,"B"), fatid)) %>%
        mutate(motid =  ifelse(motid %in% pids.to.edit,
                             paste0(motid,"B"), motid))
```

One last check to make sure all the PIDs match:

```{r}
setdiff(vcf.pid,ped$pid)
setdiff(ped$pid,vcf.pid)
```

Remember to check that the `fatid` and `motid` entries are present in the list of `pid` as well. Note that so `setdiff` should return `"0"` here, instead of `character(0)`, since rows for the parents will have a `"0"` in their `fatid` and `motid` columns, which is not in the list of `pid`.
```{r}
setdiff(ped$fatid,ped$pid)
setdiff(ped$motid,ped$pid)
```

## Write out
```{r,eval = FALSE}
filepath.ped.cleaned <- "your filepath here"
write.table(ped, filepath.ped.cleaned, sep=" ", col.names = TRUE, row.names = FALSE,quote = FALSE)
```

# Checking for Mendelian errors

Mendelian errors can be identified with the `trio.check` function in `trio`, which accepts genotype data in `trio.geno` format. We convert the VCF and PED into geno format like so:

```{r}
# allowDifference tells vcf2geno to not remove missing entries
# If you still want the missing entries to remain, set it to FALSEE
trio.geno <- vcf2geno(vcf, ped, allowDifference = TRUE)
trio.geno[1:5,1:5]
```

## Formatting the VCF for `trio.check`

Note that `trio.check` can only read in entries of the form: `"0/0"`, `"0/1"`, or `"1/1"`; missing entries (`NA` or `./.`) are not accepted. `vcf2geno` can automatically get rid of SNPs with missing entries for you, but you can check the how many missing entries there are in the `trio.geno` matrix using `table()`:

```{r}
table(trio.geno, useNA = "always")
```

### Removing SNPs that have a high rate of missingness
You can remove SNPs that have any missing entries with the below code:

```{r}
missing.cutoff <- 0.01
trio.geno <- removeSNPs(trio.geno, perc.na = missing.cutoff)
```

Check how many SNPs you have left with `dim`:
```{r}
trio.geno %>% dim
```

If you have many SNPs with a high rate of missingness (i.e., only a few SNPs are remaining), you might want to consider imputing the missing observations with BEAGLE 4.0.

### Optional: Imputing missing SNP genotypes

If it turns out you have a lot of SNPs with missing genotypes, and you want them to be included in your calculation of the number of Mendelian errors, you can choose to impute missing genotypes in the VCF by phasing it using BEAGLE 4.0, then re-create the `geno` matrix after the missing observations have been imputed, and follow the directions for common variant testing below..

#### Imputing missing genotypes with BEAGLE 4.0 in R

Install BEAGLE 4.0 by running the following code in R:

```{r,eval = FALSE}
filepath.beagle4<-"filepath/where/you/want/beagle4/to/go/here"
dl.beagle4<-paste0("wget -O ",filepath.beagle4," https://faculty.washington.edu/browning/beagle/beagle.r1399.jar")
system(dl.beagle4)
```

Phase the  VCF with the below code:

```{r,eval = FALSE}
phase.command<-paste0("java -Xmx10000m -jar ", filepath.beagle4,
                      " gt=",filepath.vcf.to.phase,
                      " ped=",filepath.ped,
                      " out=",filepath.phased.vcf)
phase.command

system(phase.command)
```

Edit the genotype entries of the phased VCF prior to running the common variants tests: `trio` can only read in genotype entries `"0/0"`, `"0/1"`, or `"1/1"`, whereas a BEAGLE-phased VCF will contain genotype entries `"0|0"`, `"0|1"`, `"1|0"`, and `"1|1"`.

```{r, eval=FALSE}
phased.vcf <- readVcf(fp.phased.vcf, hg.assembly)

#Replace '|' with '/'
geno(phased.vcf)$GT <- gsub("\\|", "\\/",geno(phased.vcf)$GT)

#Replace '0/1' with '0/1'
geno(phased.vcf)$GT[geno(phased.vcf)$GT == "1/0"] <- "0/1"

#Write out the phased VCF
filepath.phased.var.vcf<-"./data/processed_data/phased.vcf"
writeVcf(phased.vcf,filepath.phased.var.vcf)
```

Finally, re-create the `trio.geno` matrix and continue in the workflow as normal.

### Checking for correct formatting
If you need to reformat the entries of the VCF (e.g., if you have entries delimited with `|`, like `"0|0"`, or if you are using a phased VCF that has `"1/0"` entries), you can use `gsub` to replace any unwanted genotypes:

```{r,eval = FALSE}
#Replace '|' with '/'
geno(vcf)$GT <- gsub("\\|", "\\/",geno(vcf)$GT)

#Replace '0/1' with '0/1'
geno(vcf)$GT[geno(vcf)$GT == "1/0"] <- "0/1"
```

## Calculate Mendelian errors in each family

We can run `trio::trio.check` to check for Mendelian errors.  First, we add `famid` and `pid` as the first 2 columns to the `trio.geno` matrix, to format the data for `trio.check`.

```{r}
geno.with.pid <- cbind(rownames(trio.geno), trio.geno)
colnames(geno.with.pid)[1] <- c("pid")
geno.with.pid[1:5,1:5]

#Left_join to ensure that the FAMID corresponding to the PIDs in trio.geno are correct
geno.with.famid <- dplyr::left_join(data.frame(ped[, c("famid", "pid")]), 
                                    data.frame(geno.with.pid)) 
geno.with.famid[1:5,1:5]

#Make sure the genotype entries are numeric
n.col <- ncol(geno.with.famid)
geno.with.famid[, 3:n.col] <- lapply(geno.with.famid[, 3:n.col], as.character)
geno.with.famid[, 3:n.col] <- lapply(geno.with.famid[, 3:n.col], as.numeric)
geno.with.famid[1:5,1:5]
```

Now we can run `trio::trio.check`:

```{r}
trio.tmp <- trio::trio.check(dat=geno.with.famid, is.linkage=FALSE)
#takes a long time to run!
```

We can look at `trio.tmp$errors$famid` to examine the number of Mendelian errors per family:
```{r}
#This code will not run if there are no Mendelian errors
mend.err.sorted<-as.data.frame(sort(table(trio.tmp$errors$famid),
                                    decreasing = TRUE))
colnames(mend.err.sorted)<-c("famid","mend.errors")
mend.err.sorted[1:10,]
```

### Graph Mendelian errors per family
To graph the Mendelian errors, we'll use :
```{r}
n.snps <- ncol(trio.geno)
ggplot(mend.err.sorted, aes(x=famid,y=mend.errors/n.snps)) +
        geom_bar(stat="identity") +
        xlab("Family ID") + ylab("Percentage of all SNPs that have Mendelian errors") +
        theme(axis.text.x=element_blank(),
              axis.ticks.x=element_blank()
              )
```

#### Graph Mendelian errors per family at the extreme end
We'll graph the families with the 20 highest number of errors to examine the extreme end:
```{r}
ggplot(mend.err.sorted[1:20,], aes(x=famid,y=mend.errors/n.snps)) +
        geom_bar(stat="identity") +
        xlab("Family ID") + ylab("Mendelian error count") +
        theme(axis.text.x=element_text(angle = 90)
        )
```

### Remove families with high number of Mendelian errors in PED file

Based on the graph of the Mendelian error counts, there are 3 families that have the highest Mendelian error rate (15%). To remove them from analysis, we will need to remove these families in both the VCF and in the PED file.

Remove the individuals in the PED file, and write it out:

```{r}
#Check how many families there are in the raw PED
dim(ped)

#Get the famids of the families to be removed
fam.rm <- as.character(mend.err.sorted[1:3,1])
fam.rm

#Get the PIDs of the individuals in the families to be removed
pid.rm <- ped %>%
        filter(famid %in% fam.rm)
head(pid.rm)
dim(pid.rm)

#NOTE: select can be masked
pid.rm %>% select(pid)

new.ped <- ped %>%
        filter(!(famid %in% fam.rm))
```

### Remove families with high number of Mendelian errors in VCF file

Now we need to remove the individuals in the VCF. First we get a character vector of all the pids we want to keep:

```{r}
pids.to.keep <- ped %>%
        filter(!pid %in% pid.rm$pid) %>%
        select(pid) %>%
        lapply(as.character) %>%
        unlist

length(pids.to.keep)
```

#### Creating the cleaned VCF

We use the `param` argument in `readVcf()` to filter the phased VCF to only the PIDs from families without a large number of Mendelian errors.

```{r, eval = FALSE}
vcf <- VariantAnnotation::readVcf(filepath.vcf, hg.assembly,
                                  param = ScanVcfParam(sample = pids.to.keep),
)

filepath.cleaned.vcf <- "./data/processed_data/vcfs/cleaned.vcf"
writeVcf(vcf,filepath.common.vcf)
```

# Summary
Once you have gone through this workflow, you should have the following files:

1. PED file 
    + all PIDs are present in VCF file and vice versa
    + families with large numbers of Mendelian errors are removed
    + contains 6 tab-delimited columns, in the following order:
        1. **famid** - family ID
        2. **pid** - personal ID unique to every individual in the data set
        3. **fatid** - father ID (only available for child cases)
        4. **motid** - mother ID (only available for child cases)
        5. **sex** - 1 if individual is male, 0 for female
        6. **affected** - 1 if individual is affected, 0 for unaffected
   
        
2. VCF file
    + all PIDs in VCF are present in PED file and vice versa
    + families with large numbers of Mendelian errors are removed
    + genotype entries are in `"0/0"`, `"1/0"`, or `"1/1"` format
    + some `NA` values are OK (?)
        
Now you are ready to go through the [trio analysis workflow](https://github.com/lindagai/workflows/tree/master/trio%20analysis)!

# Troubleshooting

## vcf2geno() returns 'Subscript out of bounds` error

Check the type of the `pid`, `famid`, `motid`, or `fatid` variables in the PED. You can do this using

```{r}
typeof(ped$pid)
```

They should be `character` vectors. If they are `factor` or `numeric` vectors, `vcf2geno` will throw this error. You can fix this using

```{r, eval=FALSE}
ped$pid <- as.character(ped$pid)
```

or, `sapply` for all columns:

```{r, eval=FALSE}
ped <- lapply(ped, as.character)
```
